1. 消息队列如何保证高可用

Kafka的架构：是由多个broker组成，每个broker是一个节点；创建一个新的topic，这个topic会划分为多个partition分发到不同broker上，每个partition存放一部分数据；天然的分布式消息队列，就是一个topic数据分散在多个机器上，每个机器存储一部分数据；

Kafka在0.8之前是没有HA机制的，意思是创建topic后，partition数量为3个，发到三台服务器上，一个broker挂掉，就丢掉1/3数据。Kafka在0.8后，提供了HA机制也就是replication副本机制，每个节点partition数据同步到其他机器上，形成自己的多个副本；所有副本选出一个leader，负责读写，其他从副本负责同步数据；如果要读写follower还要care数据一致性问题，复杂性高；提高容错性。

这就是高可用；

写给5年、10年后的自己，现在知道自己处于大量吸收知识成长的阶段，但为生计，需要一边学习一边复习啊，加油！

2. 如何保证消息的可靠性传输

消费端：在写程序消费Kafka数据时，一般会Kafka自动提交消费偏移量；这时就需要关闭自动提交，在程序里手动提交offset；

服务端，producer（生产者设置ack=all，将数据写入所有副本后，才算成功）；每个partition至少要2个副本；

3. Redis 有哪些数据类型及应用场景

1. String 类型，存储键值对，k,v，可以用来计数；
2. Hash，存储结构化对象，可以针对对象值进行更新操作。
3. List，链表，可以通过lrange命令，做下拉列表；
4. set,去重；
5. sorted set，有序集合，根据商品id打分，然后可以倒序取出，做热门排行榜。

